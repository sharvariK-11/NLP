{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_IDF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+j9PpIJrIDoKg3Xign9MW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharvariK-11/NLP/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CunEv6Dd0VB"
      },
      "source": [
        "### TF_IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNYepzeud5Wb"
      },
      "source": [
        "Term freq. and inverse document frequency\n",
        "final freq of word in a sentence= TF *IDF\n",
        "TF(word1) = no of rep of a word1 in a sentence/ total words in sent.\n",
        "IDF(word1) = log(total no of sentences/no of sentences that contain the word1)\n",
        "FREQUENCY of each word\n",
        "= IDF(word) * TF( word)\n",
        "\n",
        "more useful bcoz importance/weightage of a word in sentence is determined ,for eg if 'good' appears in all sentences it is not imp and hence its freq = 0 , the more imp word will have more frequency, which is helpful for sentiment analysis.\n",
        "         word1    word2    word3\n",
        "sent 1    A       0         0 \n",
        "sent 2   ..       ..      .."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvvuOMpJgFA5",
        "outputId": "4f9922d6-3aec-4c10-8b2e-bccf349ce8a1"
      },
      "source": [
        "! pip install nltk\n",
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_2AU0g1fCdl",
        "outputId": "b7e342eb-ed27-40d3-df77-e006f47cecd2"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBkHICnih3VF"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbu34ZwQh_oA"
      },
      "source": [
        "paragraph =  \"\"\"I have three visions for India. In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. \n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
        "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
        "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
        "               We have not grabbed their land, their culture, \n",
        "               their history and tried to enforce our way of life on them.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W8eBJMZi1Of"
      },
      "source": [
        "### Cleaning the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD5jJzVUi7F-"
      },
      "source": [
        "import re\n",
        "wordnet=WordNetLemmatizer()\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pbV6CMDjNyj",
        "outputId": "2cab0abd-ef50-4a7a-893e-94591127f588"
      },
      "source": [
        "corpus"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['three vision india',\n",
              " 'year history people world come invaded u captured land conquered mind',\n",
              " 'alexander onwards greek turk mogul portuguese british french dutch came looted u took',\n",
              " 'yet done nation',\n",
              " 'conquered anyone',\n",
              " 'grabbed land culture history tried enforce way life']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsRF2_TPjRKf"
      },
      "source": [
        "### Creating TF IDF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7le4lBJPjQ0f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv = TfidfVectorizer()\n",
        "X = cv.fit_transform(corpus).toarray()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OHf4El6ja17",
        "outputId": "c1e2eeca-26dd-469b-9ff6-5d45c58c90d5"
      },
      "source": [
        "X"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
              "        0.57735027, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.33301397,\n",
              "        0.33301397, 0.27307622, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.27307622,\n",
              "        0.        , 0.33301397, 0.27307622, 0.        , 0.        ,\n",
              "        0.33301397, 0.        , 0.        , 0.        , 0.33301397,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33301397, 0.33301397, 0.        ],\n",
              "       [0.28867513, 0.        , 0.28867513, 0.28867513, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28867513,\n",
              "        0.        , 0.28867513, 0.        , 0.28867513, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28867513,\n",
              "        0.        , 0.28867513, 0.        , 0.28867513, 0.        ,\n",
              "        0.28867513, 0.        , 0.28867513, 0.        , 0.28867513,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.57735027, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.57735027, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.57735027],\n",
              "       [0.        , 0.77326237, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.6340862 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.36898493, 0.        , 0.        ,\n",
              "        0.36898493, 0.        , 0.36898493, 0.        , 0.30257292,\n",
              "        0.        , 0.        , 0.30257292, 0.36898493, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.36898493, 0.        ,\n",
              "        0.        , 0.36898493, 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}